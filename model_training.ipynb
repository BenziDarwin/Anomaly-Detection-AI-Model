{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c57fd8",
   "metadata": {},
   "source": [
    "## Import neccessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bedb0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from typing import Tuple, List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46840454",
   "metadata": {},
   "source": [
    "## Import data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98eda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_ndarray(file_path: str) -> Tuple[np.ndarray, List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and converts it to a NumPy array for features and a list for labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"CSV file is empty or data is invalid\")\n",
    "    \n",
    "    feature_names = df.columns[:-1].tolist()\n",
    "    features = df.iloc[:, :-1].values\n",
    "    labels = df.iloc[:, -1].astype(str).tolist()\n",
    "    return features, labels, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776277bb",
   "metadata": {},
   "source": [
    "## Data Cleaning and class distribution functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4784ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels: List[str]) -> Tuple[np.ndarray, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Encodes string labels into numeric values.\n",
    "    \"\"\"\n",
    "    unique_labels = sorted(set(labels))\n",
    "    label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    encoded_labels = np.array([label_map[label] for label in labels])\n",
    "    return encoded_labels, label_map\n",
    "\n",
    "def split_data(features: np.ndarray, labels: np.ndarray, test_size: float = 0.2) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets.\n",
    "    \"\"\"\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def clean_data(features: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cleans the feature matrix by replacing invalid values with finite values.\n",
    "    \"\"\"\n",
    "    cleaned_features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return cleaned_features\n",
    "\n",
    "def import_model(filepath: str) -> Tuple[DecisionTreeClassifier, Dict[str, int], List[str]]:\n",
    "    \"\"\"\n",
    "    Imports the model and metadata using joblib.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"File {filepath} not found\")\n",
    "    \n",
    "    data = joblib.load(filepath)\n",
    "    return data['model'], data['label_map'], data['selected_features']\n",
    "\n",
    "def analyze_class_distribution(labels: List[str], title: str = \"Class Distribution\") -> None:\n",
    "    \"\"\"\n",
    "    Analyzes and prints the distribution of classes in the dataset.\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    total = len(labels)\n",
    "    \n",
    "    print(f\"\\n{title}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for label, count in zip(unique, counts):\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"Class '{label}': {count} samples ({percentage:.2f}%)\")\n",
    "    \n",
    "    imbalance_ratio = max(counts) / min(counts)\n",
    "    print(f\"\\nImbalance Ratio (majority:minority): {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "def calculate_class_weights(labels: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculates balanced class weights inversely proportional to class frequencies.\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    n_samples = len(labels)\n",
    "    n_classes = len(unique)\n",
    "    \n",
    "    weights = {label: n_samples / (n_classes * count) for label, count in zip(unique, counts)}\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75208492",
   "metadata": {},
   "source": [
    "## Feature engineering and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_features(features: np.ndarray, labels: np.ndarray, feature_names: List[str], n_features: int = 10) -> Tuple[np.ndarray, List[str], List[int]]:\n",
    "    \"\"\"\n",
    "    Selects top N features based on importance scores using actual labels.\n",
    "    \"\"\"\n",
    "    # Train a preliminary model with actual labels to get feature importance\n",
    "    prelim_model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "    prelim_model.fit(features, labels)\n",
    "    \n",
    "    # Get indices of top N features\n",
    "    importances = prelim_model.feature_importances_\n",
    "    top_indices = np.argsort(importances)[::-1][:n_features]\n",
    "    \n",
    "    # Select top features and their names\n",
    "    selected_features = features[:, top_indices]\n",
    "    selected_names = [feature_names[i] for i in top_indices]\n",
    "    \n",
    "    print(\"\\nTop 10 features selected:\")\n",
    "    for idx, (name, importance) in enumerate(zip(selected_names, importances[top_indices]), 1):\n",
    "        print(f\"{idx}. {name} (importance: {importance:.4f})\")\n",
    "    \n",
    "    return selected_features, selected_names, top_indices.tolist()\n",
    "\n",
    "def create_feature_mapping(file_paths: List[str], selected_indices: List[int]) -> Dict[str, Dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Creates a mapping of feature indices to their names for each file.\n",
    "    \"\"\"\n",
    "    feature_mapping = {}\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        _, _, feature_names = read_csv_to_ndarray(file_path)\n",
    "        \n",
    "        file_mapping = {idx: feature_names[original_idx] \n",
    "                       for idx, original_idx in enumerate(selected_indices)}\n",
    "        feature_mapping[file_name] = file_mapping\n",
    "    \n",
    "    return feature_mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919d879",
   "metadata": {},
   "source": [
    "## SMOTE imputing for low frequency classes and sample file exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb3594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rows_with_smote(features: np.ndarray, labels: np.ndarray, n_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Adds a specific number of synthetic samples to a dataset using SMOTE.\n",
    "    \n",
    "    Args:\n",
    "        features (np.ndarray): The feature matrix\n",
    "        labels (np.ndarray): The label array\n",
    "        n_samples (int): The number of synthetic samples to generate\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: Augmented features and labels arrays\n",
    "    \"\"\"\n",
    "    # Get current class distribution\n",
    "    unique_labels, class_counts = np.unique(labels, return_counts=True)\n",
    "    n_classes = len(unique_labels)\n",
    "    \n",
    "    # Calculate how many samples to add per class (distribute evenly)\n",
    "    samples_per_class = n_samples // n_classes\n",
    "    remainder = n_samples % n_classes\n",
    "    \n",
    "    # Create sampling strategy dictionary\n",
    "    sampling_strategy = {}\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        # Add remainder samples to first classes if needed\n",
    "        extra = 1 if i < remainder else 0\n",
    "        target_count = class_counts[i] + samples_per_class + extra\n",
    "        sampling_strategy[label] = target_count\n",
    "    \n",
    "    # Apply SMOTE with the custom sampling strategy\n",
    "    smote = SMOTE(random_state=42, sampling_strategy=sampling_strategy)\n",
    "    X_resampled, y_resampled = smote.fit_resample(features, labels)\n",
    "    \n",
    "    print(f\"Added {X_resampled.shape[0] - features.shape[0]} synthetic samples using SMOTE\")\n",
    "    print(f\"Original shape: {features.shape}, New shape: {X_resampled.shape}\")\n",
    "    \n",
    "    # Analyze the distribution before and after\n",
    "    print(\"\\nClass Distribution - Before:\")\n",
    "    for label, count in zip(unique_labels, class_counts):\n",
    "        print(f\"Class {label}: {count} samples\")\n",
    "    \n",
    "    # Get new distribution\n",
    "    new_unique, new_counts = np.unique(y_resampled, return_counts=True)\n",
    "    print(\"\\nClass Distribution - After:\")\n",
    "    for label, count in zip(new_unique, new_counts):\n",
    "        print(f\"Class {label}: {count} samples\")\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def balance_classes_equal_samples(features: np.ndarray, labels: np.ndarray, n_samples_per_class: int = 20) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Balances the dataset by downsampling each class to have an equal number of samples (n_samples_per_class),\n",
    "    and shuffles the resulting dataset.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    balanced_features = []\n",
    "    balanced_labels = []\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        # Get all the indices for the current label\n",
    "        class_indices = np.where(labels == label)[0]\n",
    "        \n",
    "        # Downsample to have n_samples_per_class for each class\n",
    "        sampled_indices = resample(class_indices, n_samples=n_samples_per_class, random_state=42)\n",
    "        \n",
    "        balanced_features.append(features[sampled_indices])\n",
    "        balanced_labels.append(labels[sampled_indices])\n",
    "    \n",
    "    # Concatenate all the balanced data\n",
    "    balanced_features = np.vstack(balanced_features)\n",
    "    balanced_labels = np.concatenate(balanced_labels)\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    shuffle_indices = np.random.permutation(balanced_features.shape[0])\n",
    "    balanced_features = balanced_features[shuffle_indices]\n",
    "    balanced_labels = balanced_labels[shuffle_indices]\n",
    "    \n",
    "    return balanced_features, balanced_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d6e8f9",
   "metadata": {},
   "source": [
    "## Export functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73fd9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(model: DecisionTreeClassifier, label_map: Dict[str, int], selected_features: List[str], filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Exports the model and metadata using joblib.\n",
    "    \"\"\"\n",
    "    export_data = {\n",
    "        'model': model, \n",
    "        'label_map': label_map,\n",
    "        'selected_features': selected_features\n",
    "    }\n",
    "    joblib.dump(export_data, filepath)\n",
    "    print(f\"Model and metadata exported to {filepath}\")\n",
    "\n",
    "def export_feature_mapping(mapping: Dict[str, Dict[int, str]], filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Exports the feature mapping to a JSON file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(mapping, f, indent=2)\n",
    "    print(f\"Feature mapping exported to {filepath}\")\n",
    "\n",
    "def export_class_labels_json(label_map: Dict[str, int], filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Exports the class label mapping (from label to numeric encoding) to a JSON file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(label_map, f, indent=2)\n",
    "    print(f\"Class labels exported to {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b5f8b",
   "metadata": {},
   "source": [
    "## Analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13748500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_metrics(y_true: np.ndarray, y_pred: np.ndarray, label_map: Dict[str, int]) -> None:\n",
    "    \"\"\"\n",
    "    Prints detailed classification metrics including precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    # Inverse label mapping for readable class names\n",
    "    inv_label_map = {v: k for k, v in label_map.items()}\n",
    "    \n",
    "    # Get classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=[inv_label_map[i] for i in sorted(inv_label_map.keys())])\n",
    "    \n",
    "    print(\"\\nDetailed Classification Metrics:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(report)\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n",
    "    \n",
    "    print(\"\\nPer-class Performance:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i in range(len(precision)):\n",
    "        class_name = inv_label_map[i]\n",
    "        print(f\"Class '{class_name}':\")\n",
    "        print(f\"- Precision: {precision[i]:.4f}\")\n",
    "        print(f\"- Recall: {recall[i]:.4f}\")\n",
    "        print(f\"- F1-score: {f1[i]:.4f}\")\n",
    "        print(f\"- Support: {support[i]}\")\n",
    "\n",
    "\n",
    "def perform_cross_validation(features: np.ndarray, labels: np.ndarray, n_splits: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Performs stratified k-fold cross-validation and prints results.\n",
    "    \"\"\"\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "    \n",
    "    scores = cross_val_score(model, features, labels, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"\\nCross-validation Results ({n_splits}-fold):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Mean Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    print(f\"Individual Fold Scores: {', '.join(f'{score:.4f}' for score in scores)}\")\n",
    "\n",
    "def analyze_feature_correlations(features: np.ndarray, feature_names: List[str], labels: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes and plots feature correlations to check for potential data leakage.\n",
    "    \"\"\"\n",
    "    # Create DataFrame with features and labels\n",
    "    df = pd.DataFrame(features, columns=feature_names)\n",
    "    df['label'] = labels\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = df.corr()\n",
    "    \n",
    "    # Plot correlation matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlations, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_correlations.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Check for high correlations with label\n",
    "    label_correlations = correlations['label'].abs().sort_values(ascending=False)[1:]  # Exclude self-correlation\n",
    "    print(\"\\nFeature-Label Correlations:\")\n",
    "    print(\"-\" * 40)\n",
    "    for feature, corr in label_correlations.items():\n",
    "        print(f\"{feature}: {corr:.4f}\")\n",
    "    \n",
    "    # Warning for potential data leakage\n",
    "    high_corr_features = label_correlations[label_correlations > 0.9]\n",
    "    if not high_corr_features.empty:\n",
    "        print(\"\\nWARNING: Potential data leakage detected!\")\n",
    "        print(\"The following features have very high correlation (>0.9) with the label:\")\n",
    "        for feature, corr in high_corr_features.items():\n",
    "            print(f\"- {feature}: {corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9831b8",
   "metadata": {},
   "source": [
    "## Save analysis charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3b6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature_importance_chart(model: DecisionTreeClassifier, feature_names: List[str], filepath: str):\n",
    "    \"\"\"\n",
    "    Saves a bar chart of feature importances.\n",
    "    \"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Feature Importances (Top 5 Features)\")\n",
    "    plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    print(f\"Feature importance chart saved to {filepath}\")\n",
    "\n",
    "def save_confusion_matrix(y_test: np.ndarray, predictions: np.ndarray, filepath: str):\n",
    "    \"\"\"\n",
    "    Saves a confusion matrix chart.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved to {filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a4f56",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f503e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from CSV...\n",
      "\n",
      "Analyzing class distribution...\n",
      "\n",
      "Class Distribution:\n",
      "----------------------------------------\n",
      "Class 'BENIGN': 702888 samples (70.87%)\n",
      "Class 'Bot': 1966 samples (0.20%)\n",
      "Class 'DDoS': 128027 samples (12.91%)\n",
      "Class 'Infiltration': 36 samples (0.00%)\n",
      "Class 'PortScan': 158930 samples (16.02%)\n",
      "\n",
      "Imbalance Ratio (majority:minority): 19524.67:1\n",
      "\n",
      "Cleaning data...\n",
      "Encoding labels...\n",
      "\n",
      "Adding synthetic samples for Bot and Infiltration classes...\n",
      "Added 100000 synthetic samples using SMOTE\n",
      "Original shape: (2002, 78), New shape: (102002, 78)\n",
      "\n",
      "Class Distribution - Before:\n",
      "Class 1: 1966 samples\n",
      "Class 3: 36 samples\n",
      "\n",
      "Class Distribution - After:\n",
      "Class 1: 51966 samples\n",
      "Class 3: 50036 samples\n",
      "\n",
      "Final distribution after adding synthetic samples:\n",
      "BENIGN: 702888 samples\n",
      "Bot: 51966 samples\n",
      "DDoS: 128027 samples\n",
      "Infiltration: 50036 samples\n",
      "PortScan: 158930 samples\n",
      "Class labels exported to class_labels.json\n",
      "\n",
      "Selecting top 10 features...\n",
      "\n",
      "Top 10 features selected:\n",
      "1. Total Length of Fwd Packets (importance: 0.2311)\n",
      "2. Flow Bytes/s (importance: 0.1966)\n",
      "3.  Bwd Packet Length Std (importance: 0.1963)\n",
      "4.  Active Min (importance: 0.0750)\n",
      "5.  Subflow Bwd Packets (importance: 0.0641)\n",
      "6.  Destination Port (importance: 0.0544)\n",
      "7.  Init_Win_bytes_backward (importance: 0.0528)\n",
      "8. Init_Win_bytes_forward (importance: 0.0347)\n",
      "9.  Packet Length Mean (importance: 0.0321)\n",
      "10.  Min Packet Length (importance: 0.0286)\n",
      "\n",
      "Balancing dataset by equal sampling of each class and shuffling...\n",
      "Balanced and shuffled dataset saved to 'balanced_shuffled_dataset.csv'\n",
      "\n",
      "Performing cross-validation...\n",
      "\n",
      "Cross-validation Results (5-fold):\n",
      "----------------------------------------\n",
      "Mean Accuracy: 0.9899 (+/- 0.0004)\n",
      "Individual Fold Scores: 0.9898, 0.9900, 0.9896, 0.9900, 0.9900\n",
      "\n",
      "Analyzing feature correlations...\n",
      "\n",
      "Feature-Label Correlations:\n",
      "----------------------------------------\n",
      " Min Packet Length: 0.3490\n",
      "Init_Win_bytes_forward: 0.1957\n",
      "Total Length of Fwd Packets: 0.1297\n",
      " Bwd Packet Length Std: 0.1256\n",
      " Active Min: 0.1173\n",
      " Init_Win_bytes_backward: 0.0897\n",
      " Destination Port: 0.0849\n",
      " Subflow Bwd Packets: 0.0645\n",
      " Packet Length Mean: 0.0587\n",
      "Flow Bytes/s: 0.0289\n",
      "Feature mapping exported to feature_mapping.json\n",
      "\n",
      "Splitting data...\n",
      "Training final model...\n",
      "Making predictions...\n",
      "\n",
      "Detailed Classification Metrics:\n",
      "----------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.99      1.00      0.99    140907\n",
      "         Bot       0.98      0.93      0.95     10382\n",
      "        DDoS       1.00      0.97      0.99     25546\n",
      "Infiltration       1.00      0.97      0.98      9913\n",
      "    PortScan       0.99      1.00      1.00     31622\n",
      "\n",
      "    accuracy                           0.99    218370\n",
      "   macro avg       0.99      0.97      0.98    218370\n",
      "weighted avg       0.99      0.99      0.99    218370\n",
      "\n",
      "\n",
      "Per-class Performance:\n",
      "----------------------------------------\n",
      "Class 'BENIGN':\n",
      "- Precision: 0.9872\n",
      "- Recall: 0.9969\n",
      "- F1-score: 0.9920\n",
      "- Support: 140907\n",
      "Class 'Bot':\n",
      "- Precision: 0.9761\n",
      "- Recall: 0.9288\n",
      "- F1-score: 0.9519\n",
      "- Support: 10382\n",
      "Class 'DDoS':\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9723\n",
      "- F1-score: 0.9859\n",
      "- Support: 25546\n",
      "Class 'Infiltration':\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9677\n",
      "- F1-score: 0.9836\n",
      "- Support: 9913\n",
      "Class 'PortScan':\n",
      "- Precision: 0.9935\n",
      "- Recall: 0.9982\n",
      "- F1-score: 0.9958\n",
      "- Support: 31622\n",
      "\n",
      "Final Model Accuracy: 98.96%\n",
      "Model and metadata exported to decision_tree_model.pkl\n",
      "Feature importance chart saved to feature_importance.png\n",
      "Confusion matrix saved to confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\n",
    "    \"./data/1.csv\",\n",
    "    \"./data/2.csv\",\n",
    "    \"./data/3.csv\",\n",
    "    \"./data/4.csv\"\n",
    "]\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_feature_names = []\n",
    "\n",
    "print(\"Reading data from CSV...\")\n",
    "for file_path in file_paths:\n",
    "    features, labels, feature_names = read_csv_to_ndarray(file_path)\n",
    "    all_features.append(features)\n",
    "    all_labels.extend(labels)\n",
    "    if not all_feature_names:\n",
    "        all_feature_names = feature_names\n",
    "\n",
    "features = np.vstack(all_features)\n",
    "\n",
    "# Analyze class distribution\n",
    "print(\"\\nAnalyzing class distribution...\")\n",
    "analyze_class_distribution(all_labels)\n",
    "\n",
    "print(\"\\nCleaning data...\")\n",
    "features = clean_data(features)\n",
    "\n",
    "print(\"Encoding labels...\")\n",
    "encoded_labels, label_map = encode_labels(all_labels)\n",
    "\n",
    "# Add synthetic samples using SMOTE only for Bot and Infiltration classes\n",
    "print(\"\\nAdding synthetic samples for Bot and Infiltration classes...\")\n",
    "\n",
    "# 1. Extract only Bot (1) and Infiltration (3) samples\n",
    "target_classes = [1, 3]  # Bot and Infiltration\n",
    "target_mask = np.isin(encoded_labels, target_classes)\n",
    "target_features = features[target_mask]\n",
    "target_labels = encoded_labels[target_mask]\n",
    "\n",
    "# 2. Generate synthetic samples for just these classes\n",
    "synthetic_features, synthetic_labels = add_rows_with_smote(\n",
    "    target_features, target_labels, n_samples=100000\n",
    ")\n",
    "\n",
    "# 3. Get only the newly generated samples\n",
    "original_count = len(target_labels)\n",
    "new_samples_features = synthetic_features[original_count:]\n",
    "new_samples_labels = synthetic_labels[original_count:]\n",
    "\n",
    "# 4. Add them back to the original dataset\n",
    "features = np.vstack([features, new_samples_features])\n",
    "encoded_labels = np.concatenate([encoded_labels, new_samples_labels])\n",
    "\n",
    "# Display final distribution\n",
    "unique_final, counts_final = np.unique(encoded_labels, return_counts=True)\n",
    "class_names = {v: k for k, v in label_map.items()}\n",
    "print(\"\\nFinal distribution after adding synthetic samples:\")\n",
    "for label, count in zip(unique_final, counts_final):\n",
    "    print(f\"{class_names.get(label, f'Class {label}')}: {count} samples\")\n",
    "\n",
    "export_class_labels_json(label_map, \"class_labels.json\")\n",
    "\n",
    "print(\"\\nSelecting top 10 features...\")\n",
    "selected_features, selected_names, selected_indices = select_top_features(\n",
    "    features, encoded_labels, all_feature_names\n",
    ")\n",
    "\n",
    "# Balance dataset by equal sampling and shuffle\n",
    "print(\"\\nBalancing dataset by equal sampling of each class and shuffling...\")\n",
    "balanced_features, balanced_labels = balance_classes_equal_samples(features, encoded_labels, n_samples_per_class=20)\n",
    "\n",
    "# Save balanced and shuffled dataset to CSV\n",
    "balanced_df = pd.DataFrame(balanced_features, columns=all_feature_names)\n",
    "balanced_df['label'] = balanced_labels\n",
    "balanced_df.to_csv(\"balanced_shuffled_dataset.csv\", index=False)\n",
    "print(\"Balanced and shuffled dataset saved to 'balanced_shuffled_dataset.csv'\")\n",
    "\n",
    "# Perform cross-validation\n",
    "print(\"\\nPerforming cross-validation...\")\n",
    "perform_cross_validation(selected_features, encoded_labels)\n",
    "\n",
    "# Analyze feature correlations\n",
    "print(\"\\nAnalyzing feature correlations...\")\n",
    "analyze_feature_correlations(selected_features, selected_names, encoded_labels)\n",
    "\n",
    "# Create and export feature mapping\n",
    "feature_mapping = create_feature_mapping(file_paths, selected_indices)\n",
    "export_feature_mapping(feature_mapping, \"feature_mapping.json\")\n",
    "\n",
    "# Split data and train final model\n",
    "print(\"\\nSplitting data...\")\n",
    "x_train, y_train, x_test, y_test = split_data(selected_features, encoded_labels)\n",
    "\n",
    "print(\"Training final model...\")\n",
    "model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Print detailed classification metrics\n",
    "print_classification_metrics(y_test, predictions, label_map)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nFinal Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "export_model(model, label_map, selected_names, \"decision_tree_model.pkl\")\n",
    "\n",
    "# Save feature importance chart using selected feature names\n",
    "save_feature_importance_chart(model, selected_names, filepath=\"feature_importance.png\")\n",
    "\n",
    "# Save confusion matrix\n",
    "save_confusion_matrix(y_test, predictions, filepath=\"confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
