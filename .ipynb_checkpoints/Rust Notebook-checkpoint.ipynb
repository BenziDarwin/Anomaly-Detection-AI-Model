{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1afde7fc",
   "metadata": {},
   "source": [
    "## Add project dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb71df85-3d95-41bc-8234-344b440a0b3c",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    ":dep csv = { version = \"1.1\" }\n",
    ":dep ndarray = { version = \"0.15.6\" }\n",
    ":dep linfa = { version = \"0.7.0\" }\n",
    ":dep linfa-trees = { version = \"0.7\" }\n",
    ":dep ndarray-rand = { version = \"0.15.0\" }\n",
    ":dep plotters = { version = \"0.3.7\" }\n",
    ":dep bincode = {version = \"1.3.3\"}\n",
    ":dep serde = { version = \"1.0\", features = [\"derive\"] }\n",
    "\n",
    "\n",
    "use csv::ReaderBuilder;\n",
    "use ndarray::{Array1, Array2, Axis, stack, ArrayBase, Data, Ix2};\n",
    "use linfa::prelude::*;\n",
    "use linfa_trees::DecisionTree;\n",
    "use std::collections::HashMap;\n",
    "use std::error::Error;\n",
    "use std::fs::File;\n",
    "use std::io::{Write, Read};\n",
    "use serde::{Serialize, Deserialize};\n",
    "use bincode;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227c867",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "source": [
    "## Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc1c8a76",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "fn read_csv_to_ndarray(file_path: &str) -> Result<(Array2<f64>, Vec<String>), Box<dyn Error>> {\n",
    "    let mut reader = ReaderBuilder::new()\n",
    "        .has_headers(true)\n",
    "        .from_path(file_path)?;\n",
    "    \n",
    "    let mut features = Vec::new();\n",
    "    let mut labels = Vec::new();\n",
    "    let mut row_count = 0;\n",
    "    let mut col_count = 0;\n",
    "    \n",
    "    for result in reader.records() {\n",
    "        let record = result?;\n",
    "        row_count += 1;\n",
    "        \n",
    "        let row: Vec<f64> = record\n",
    "            .iter()\n",
    "            .take(record.len() - 1)\n",
    "            .filter_map(|field| field.parse::<f64>().ok())\n",
    "            .collect();\n",
    "        \n",
    "        if row_count == 1 {\n",
    "            col_count = row.len();\n",
    "        } else if row.len() != col_count {\n",
    "            return Err(format!(\"Inconsistent column count at row {}\", row_count).into());\n",
    "        }\n",
    "        \n",
    "        features.extend(row);\n",
    "        labels.push(record[record.len() - 1].to_string());\n",
    "    }\n",
    "    \n",
    "    if features.is_empty() || labels.is_empty() {\n",
    "        return Err(\"CSV file is empty or data is invalid\".into());\n",
    "    }\n",
    "    \n",
    "    let feature_array = Array2::from_shape_vec((row_count, col_count), features)?;\n",
    "    Ok((feature_array, labels))\n",
    "}\n",
    "\n",
    "fn encode_labels(labels: &[String]) -> (Vec<usize>, HashMap<String, usize>) {\n",
    "    let mut label_map = HashMap::new();\n",
    "    let mut encoded_labels = Vec::new();\n",
    "    let mut next_label = 0;\n",
    "\n",
    "    for label in labels {\n",
    "        let encoded_label = *label_map.entry(label.clone()).or_insert_with(|| {\n",
    "            let current = next_label;\n",
    "            next_label += 1;\n",
    "            current\n",
    "        });\n",
    "        encoded_labels.push(encoded_label);\n",
    "    }\n",
    "\n",
    "    (encoded_labels, label_map)\n",
    "}\n",
    "\n",
    "fn split_data(\n",
    "    features: &ArrayBase<impl Data<Elem = f64>, Ix2>,\n",
    "    labels: &[usize],\n",
    ") -> (Array2<f64>, Array1<usize>, Array2<f64>, Array1<usize>) {\n",
    "    let total_rows = features.nrows();\n",
    "    let train_size = (total_rows as f64 * 0.8) as usize;\n",
    "\n",
    "    let x_train = features.slice(s![..train_size, ..]).to_owned();\n",
    "    let y_train = Array1::from_iter(labels[..train_size].iter().cloned());\n",
    "\n",
    "    let x_test = features.slice(s![train_size.., ..]).to_owned();\n",
    "    let y_test = Array1::from_iter(labels[train_size..].iter().cloned());\n",
    "\n",
    "    (x_train, y_train, x_test, y_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e87788e8-c625-4373-b8ac-d8bc0e67ae45",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "unnecessary parentheses around type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m[unused_parens] Error:\u001b[0m unnecessary parentheses around type"
     ]
    },
    {
     "ename": "Error",
     "evalue": "unnecessary parentheses around function argument",
     "output_type": "error",
     "traceback": [
      "\u001b[31m[unused_parens] Error:\u001b[0m unnecessary parentheses around function argument"
     ]
    },
    {
     "ename": "Error",
     "evalue": "mismatched types",
     "output_type": "error",
     "traceback": [
      "\u001b[31m[E0308] Error:\u001b[0m mismatched types",
      "     \u001b[38;5;246m╭\u001b[0m\u001b[38;5;246m─\u001b[0m\u001b[38;5;246m[\u001b[0mcommand_35:1:1\u001b[38;5;246m]\u001b[0m",
      "     \u001b[38;5;246m│\u001b[0m",
      " \u001b[38;5;246m134 │\u001b[0m \u001b[38;5;249m \u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249ml\u001b[0m\u001b[38;5;249me\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249m(\u001b[0m\u001b[38;5;249mx\u001b[0m\u001b[38;5;249m_\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249mr\u001b[0m\u001b[38;5;249ma\u001b[0m\u001b[38;5;249mi\u001b[0m\u001b[38;5;249mn\u001b[0m\u001b[38;5;249m,\u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249my\u001b[0m\u001b[38;5;249m_\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249mr\u001b[0m\u001b[38;5;249ma\u001b[0m\u001b[38;5;249mi\u001b[0m\u001b[38;5;249mn\u001b[0m\u001b[38;5;249m,\u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249mx\u001b[0m\u001b[38;5;249m_\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249me\u001b[0m\u001b[38;5;249ms\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249m,\u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249my\u001b[0m\u001b[38;5;249m_\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249me\u001b[0m\u001b[38;5;249ms\u001b[0m\u001b[38;5;249mt\u001b[0m\u001b[38;5;249m)\u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249m=\u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;100ms\u001b[0m\u001b[38;5;100mp\u001b[0m\u001b[38;5;100ml\u001b[0m\u001b[38;5;100mi\u001b[0m\u001b[38;5;100mt\u001b[0m\u001b[38;5;100m_\u001b[0m\u001b[38;5;100md\u001b[0m\u001b[38;5;100ma\u001b[0m\u001b[38;5;100mt\u001b[0m\u001b[38;5;100ma\u001b[0m\u001b[38;5;249m(\u001b[0m\u001b[38;5;54m&\u001b[0m\u001b[38;5;54md\u001b[0m\u001b[38;5;54ma\u001b[0m\u001b[38;5;54mt\u001b[0m\u001b[38;5;54ma\u001b[0m\u001b[38;5;249m,\u001b[0m\u001b[38;5;249m \u001b[0m\u001b[38;5;249me\u001b[0m\u001b[38;5;249mn\u001b[0m\u001b[38;5;249mc\u001b[0m\u001b[38;5;249mo\u001b[0m\u001b[38;5;249md\u001b[0m\u001b[38;5;249me\u001b[0m\u001b[38;5;249md\u001b[0m\u001b[38;5;249m_\u001b[0m\u001b[38;5;249ml\u001b[0m\u001b[38;5;249ma\u001b[0m\u001b[38;5;249mb\u001b[0m\u001b[38;5;249me\u001b[0m\u001b[38;5;249ml\u001b[0m\u001b[38;5;249ms\u001b[0m\u001b[38;5;249m)\u001b[0m\u001b[38;5;249m;\u001b[0m",
      " \u001b[38;5;240m    │\u001b[0m                                              \u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m┬\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m \u001b[38;5;54m─\u001b[0m\u001b[38;5;54m─\u001b[0m\u001b[38;5;54m┬\u001b[0m\u001b[38;5;54m─\u001b[0m\u001b[38;5;54m─\u001b[0m  ",
      " \u001b[38;5;240m    │\u001b[0m                                                   \u001b[38;5;100m╰\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m\u001b[38;5;100m─\u001b[0m arguments to this function are incorrect",
      " \u001b[38;5;240m    │\u001b[0m                                                           \u001b[38;5;54m│\u001b[0m    ",
      " \u001b[38;5;240m    │\u001b[0m                                                           \u001b[38;5;54m╰\u001b[0m\u001b[38;5;54m─\u001b[0m\u001b[38;5;54m─\u001b[0m\u001b[38;5;54m─\u001b[0m\u001b[38;5;54m─\u001b[0m expected an array with a fixed size of 2 elements, found one with 3 elements",
      "\u001b[38;5;246m─────╯\u001b[0m"
     ]
    }
   ],
   "source": [
    "#[derive(Serialize, Deserialize)]\n",
    "struct ExportableModel {\n",
    "    label_map: HashMap<String, usize>,\n",
    "    max_depth: Option<usize>,\n",
    "    min_weight_leaf: f64,\n",
    "    // Add other necessary model parameters\n",
    "}\n",
    "\n",
    "fn export_model(\n",
    "    _model: &DecisionTree<f64, usize>, \n",
    "    label_map: &HashMap<String, usize>, \n",
    "    filepath: &str\n",
    ") -> Result<(), Box<dyn Error>> {\n",
    "    let exportable_model = ExportableModel {\n",
    "        label_map: label_map.clone(),\n",
    "        max_depth: Some(10), // Extract from model configuration\n",
    "        min_weight_leaf: 1.0, // Extract from model configuration\n",
    "    };\n",
    "    \n",
    "    let encoded = bincode::serialize(&exportable_model)?;\n",
    "    let mut file = File::create(filepath)?;\n",
    "    file.write_all(&encoded)?;\n",
    "    \n",
    "    println!(\"Model metadata exported to {}\", filepath);\n",
    "    Ok(())\n",
    "}\n",
    "\n",
    "fn import_model(filepath: &str) -> Result<(HashMap<String, usize>), Box<dyn Error>> {\n",
    "    let mut file = File::open(filepath)?;\n",
    "    let mut buffer = Vec::new();\n",
    "    file.read_to_end(&mut buffer)?;\n",
    "    \n",
    "    let exportable_model: ExportableModel = bincode::deserialize(&buffer)?;\n",
    "    \n",
    "    Ok((exportable_model.label_map))\n",
    "}\n",
    "\n",
    "fn read_csv_to_ndarray(file_path: &str) -> Result<(Array2<f64>, Vec<String>), Box<dyn Error>> {\n",
    "    let mut reader = ReaderBuilder::new()\n",
    "        .has_headers(true)\n",
    "        .from_path(file_path)?;\n",
    "    \n",
    "    let mut features = Vec::new();\n",
    "    let mut labels = Vec::new();\n",
    "    let mut row_count = 0;\n",
    "    let mut col_count = 0;\n",
    "    \n",
    "    for result in reader.records() {\n",
    "        let record = result?;\n",
    "        row_count += 1;\n",
    "        \n",
    "        let row: Vec<f64> = record\n",
    "            .iter()\n",
    "            .take(record.len() - 1)\n",
    "            .filter_map(|field| field.parse::<f64>().ok())\n",
    "            .collect();\n",
    "        \n",
    "        if row_count == 1 {\n",
    "            col_count = row.len();\n",
    "        } else if row.len() != col_count {\n",
    "            return Err(format!(\"Inconsistent column count at row {}\", row_count).into());\n",
    "        }\n",
    "        \n",
    "        features.extend(row);\n",
    "        labels.push(record[record.len() - 1].to_string());\n",
    "    }\n",
    "    \n",
    "    if features.is_empty() || labels.is_empty() {\n",
    "        return Err(\"CSV file is empty or data is invalid\".into());\n",
    "    }\n",
    "    \n",
    "    let feature_array = Array2::from_shape_vec((row_count, col_count), features)?;\n",
    "    Ok((feature_array, labels))\n",
    "}\n",
    "\n",
    "fn encode_labels(labels: &[String]) -> (Vec<usize>, HashMap<String, usize>) {\n",
    "    let mut label_map = HashMap::new();\n",
    "    let mut encoded_labels = Vec::new();\n",
    "    let mut next_label = 0;\n",
    "\n",
    "    for label in labels {\n",
    "        let encoded_label = *label_map.entry(label.clone()).or_insert_with(|| {\n",
    "            let current = next_label;\n",
    "            next_label += 1;\n",
    "            current\n",
    "        });\n",
    "        encoded_labels.push(encoded_label);\n",
    "    }\n",
    "\n",
    "    (encoded_labels, label_map)\n",
    "}\n",
    "\n",
    "fn split_data(\n",
    "    features: &ArrayBase<impl Data<Elem = f64>, Ix2>, \n",
    "    labels: Vec<usize>\n",
    ") -> (Array2<f64>, Array1<usize>, Array2<f64>, Array1<usize>) {\n",
    "    let total_rows = features.nrows();\n",
    "    let train_size = (total_rows as f64 * 0.8) as usize;\n",
    "\n",
    "    let x_train = features.slice(s![..train_size, ..]).to_owned();\n",
    "    let y_train = Array1::from_vec(labels[..train_size].to_vec());\n",
    "    \n",
    "    let x_test = features.slice(s![train_size.., ..]).to_owned();\n",
    "    let y_test = Array1::from_vec(labels[train_size..].to_vec());\n",
    "\n",
    "    (x_train, y_train, x_test, y_test)\n",
    "}\n",
    "\n",
    "fn run_main() -> Result<DecisionTree<f64, usize>, Box<dyn Error>> {\n",
    "    let file_paths = vec![\n",
    "        \"./data/1.csv\",\n",
    "        \"./data/2.csv\",\n",
    "        \"./data/3.csv\",\n",
    "        \"./data/4.csv\",\n",
    "    ];\n",
    "    \n",
    "    println!(\"Reading data from CSV...\");\n",
    "    let mut all_data = Vec::new();\n",
    "    let mut all_labels = Vec::new();\n",
    "\n",
    "    for file_path in file_paths {\n",
    "        let (data, labels) = read_csv_to_ndarray(file_path)?;\n",
    "        all_data.push(data);\n",
    "        all_labels.extend(labels);\n",
    "    }\n",
    "    \n",
    "    let views: Vec<_> = all_data.iter().map(|arr| arr.view()).collect();\n",
    "    let data = stack(Axis(0), views.as_slice())?;\n",
    "    \n",
    "    println!(\"Encoding labels...\");\n",
    "    let (encoded_labels, label_map) = encode_labels(&all_labels);\n",
    "    \n",
    "    println!(\"Splitting data...\");\n",
    "    let (x_train, y_train, x_test, y_test) = split_data(&data, encoded_labels);\n",
    "    \n",
    "    println!(\"Training model...\");\n",
    "    let model = DecisionTree::params()\n",
    "        .max_depth(Some(10))\n",
    "        .min_weight_leaf(1.0)\n",
    "        .fit(&Dataset::new(x_train, y_train))\n",
    "        .expect(\"Failed to train model\");\n",
    "    \n",
    "    println!(\"Making predictions...\");\n",
    "    let predictions = model.predict(&x_test);\n",
    "    \n",
    "    let accuracy = predictions\n",
    "        .iter()\n",
    "        .zip(y_test.iter())\n",
    "        .filter(|(&pred, &actual)| pred == actual)\n",
    "        .count() as f64\n",
    "        / y_test.len() as f64;\n",
    "    \n",
    "    println!(\"Model accuracy: {:.2}%\", accuracy * 100.0);\n",
    "    \n",
    "    export_model(&model, &label_map, \"decision_tree_model.bin\")?;\n",
    "    \n",
    "    Ok(model)\n",
    "}\n",
    "\n",
    "fn main() -> Result<(), Box<dyn Error>> {\n",
    "    run_main()?;\n",
    "    \n",
    "    let imported_label_map = import_model(\"decision_tree_model.bin\")?;\n",
    "    println!(\"Imported label map: {:?}\", imported_label_map);\n",
    "    \n",
    "    Ok(())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc1c05",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026bb564",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19634332-63d0-4d33-8a74-528b96f4edce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
