{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71df85-3d95-41bc-8234-344b440a0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    ":dep csv = { version = \"1.1\" }\n",
    ":dep ndarray = { version = \"0.13.1\" }\n",
    ":dep linfa = { version = \"0.7.0\" }\n",
    ":dep linfa-trees = { version = \"0.7\" }\n",
    ":dep ndarray-rand = { version = \"0.15.0\" }\n",
    ":dep plotters = { version = \"0.3.7\" }\n",
    "\n",
    "extern crate csv;\n",
    "extern crate ndarray;\n",
    "extern crate linfa;\n",
    "extern crate linfa-trees;\n",
    "extern crate ndarray-rand;\n",
    "extern crate plotters;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7b5eb-9797-4bdc-bc3d-d2c31d90cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "use csv::ReaderBuilder;\n",
    "use ndarray::{Array1, Array2, s};\n",
    "use linfa::prelude::*;\n",
    "use linfa_trees::DecisionTree;\n",
    "use std::collections::HashMap;\n",
    "use std::error::Error;\n",
    "use plotters::prelude::*;\n",
    "\n",
    "// Function to map labels to numeric values for classification\n",
    "fn encode_labels(labels: Vec<String>) -> (Array1<usize>, HashMap<String, usize>) {\n",
    "    let mut label_map = HashMap::new();\n",
    "    let mut current_label = 0;\n",
    "    let encoded_labels: Vec<usize> = labels\n",
    "        .into_iter()\n",
    "        .map(|label| {\n",
    "            *label_map.entry(label).or_insert_with(|| {\n",
    "                let val = current_label;\n",
    "                current_label += 1;\n",
    "                val\n",
    "            })\n",
    "        })\n",
    "        .collect();\n",
    "    let array = Array1::from_vec(encoded_labels);\n",
    "    (array, label_map)\n",
    "}\n",
    "\n",
    "// Function to read CSV into an ndarray with chunked reading\n",
    "fn read_csv_to_ndarray(file_path: &str) -> Result<(Array2<f64>, Vec<String>), Box<dyn Error>> {\n",
    "    let mut reader = ReaderBuilder::new()\n",
    "        .has_headers(true)\n",
    "        .from_path(file_path)?;\n",
    "    \n",
    "    let mut features = Vec::new();\n",
    "    let mut labels = Vec::new();\n",
    "    let mut row_count = 0;\n",
    "    \n",
    "    for result in reader.records() {\n",
    "        let record = result?;\n",
    "        row_count += 1;\n",
    "        if row_count == 1 {\n",
    "            let col_count = record.len() - 1;\n",
    "            features = Vec::with_capacity(row_count * col_count);\n",
    "            labels = Vec::with_capacity(row_count);\n",
    "        }\n",
    "        \n",
    "        let row: Vec<f64> = record\n",
    "            .iter()\n",
    "            .take(record.len() - 1)\n",
    "            .filter_map(|field| field.parse::<f64>().ok())\n",
    "            .collect();\n",
    "            \n",
    "        if row.len() == record.len() - 1 {\n",
    "            features.extend(row);\n",
    "            labels.push(record[record.len() - 1].to_string());\n",
    "        }\n",
    "    }\n",
    "\n",
    "    let num_cols = if !features.is_empty() { features.len() / labels.len() } else { 0 };\n",
    "    let feature_array = Array2::from_shape_vec((labels.len(), num_cols), features)?;\n",
    "    \n",
    "    Ok((feature_array, labels))\n",
    "}\n",
    "\n",
    "// Function to split data into training and testing sets\n",
    "fn split_data(data: Array2<f64>, targets: Array1<usize>) -> (Array2<f64>, Array1<usize>, Array2<f64>, Array1<usize>) {\n",
    "    let num_samples = data.nrows();\n",
    "    let split_at = (num_samples as f64 * 0.8) as usize;\n",
    "    \n",
    "    let x_train = data.slice(s![..split_at, ..]).to_owned();\n",
    "    let y_train = targets.slice(s![..split_at]).to_owned();\n",
    "    let x_test = data.slice(s![split_at.., ..]).to_owned();\n",
    "    let y_test = targets.slice(s![split_at..]).to_owned();\n",
    "    \n",
    "    (x_train, y_train, x_test, y_test)\n",
    "}\n",
    "\n",
    "// Function to visualize the relation between features and target labels\n",
    "fn plot_data(features: &Array2<f64>, targets: &Array1<usize>, file_name: &str) -> Result<(), Box<dyn Error>> {\n",
    "    let root = BitMapBackend::new(file_name, (800, 600)).into_drawing_area();\n",
    "    root.fill(&WHITE)?;\n",
    "    let mut chart = ChartBuilder::on(&root)\n",
    "        .caption(\"Feature Relationships\", (\"sans-serif\", 40).into_font())\n",
    "        .margin(10)\n",
    "        .x_label_area_size(30)\n",
    "        .y_label_area_size(30)\n",
    "        .build_cartesian_2d(0..features.nrows(), 0..features.ncols())?;\n",
    "\n",
    "    chart.configure_mesh().draw()?;\n",
    "    for (i, row) in features.outer_iter().enumerate() {\n",
    "        let label = targets[i] as i32;\n",
    "        chart.draw_series(PointSeries::of_element(\n",
    "            row.iter().enumerate().map(|(x, &y)| (x as i32, y as i32)),\n",
    "            5,\n",
    "            &Palette99::pick(label),\n",
    "            &|c, s, st| {\n",
    "                return EmptyElement::at(c)\n",
    "                    + Circle::new((0, 0), s, st.filled());\n",
    "            },\n",
    "        ))?;\n",
    "    }\n",
    "    Ok(())\n",
    "}\n",
    "\n",
    "fn main() -> Result<(), Box<dyn Error>> {\n",
    "    let file_path = \"data/train.csv\";\n",
    "    \n",
    "    println!(\"Reading data from CSV...\");\n",
    "    let (data, labels) = read_csv_to_ndarray(file_path)?;\n",
    "    \n",
    "    println!(\"Encoding labels...\");\n",
    "    let (encoded_labels, label_map) = encode_labels(labels);\n",
    "    \n",
    "    println!(\"Splitting data...\");\n",
    "    let (x_train, y_train, x_test, y_test) = split_data(data, encoded_labels);\n",
    "    \n",
    "    println!(\"Creating datasets...\");\n",
    "    let train_dataset = Dataset::from((x_train.clone(), y_train.clone()));\n",
    "    let test_dataset = Dataset::from((x_test.clone(), y_test.clone()));\n",
    "    \n",
    "    println!(\"Training model...\");\n",
    "    let model = DecisionTree::params()\n",
    "        .max_depth(Some(10))\n",
    "        .min_weight_leaf(1.0)\n",
    "        .fit(&train_dataset)\n",
    "        .expect(\"Failed to train model\");\n",
    "    \n",
    "    println!(\"Making predictions...\");\n",
    "    let predictions = model.predict(&test_dataset);\n",
    "    \n",
    "    let accuracy = predictions\n",
    "        .iter()\n",
    "        .zip(test_dataset.targets().iter())\n",
    "        .filter(|(&pred, &actual)| pred == actual)\n",
    "        .count() as f64\n",
    "        / test_dataset.targets().len() as f64;\n",
    "    \n",
    "    println!(\"Model accuracy: {:.2}%\", accuracy * 100.0);\n",
    "    println!(\"Label encoding map: {:?}\", label_map);\n",
    "    \n",
    "    // Visualize the training data\n",
    "    plot_data(&x_train, &y_train, \"train_plot.png\")?;\n",
    "    \n",
    "    Ok(())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d02e7b-c8df-4a72-abe9-ed3356ba8410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
